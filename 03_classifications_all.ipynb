{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ad314a-89e1-4329-be00-19367db3dff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Path to your Excel file\n",
    "file_path = r'C:\\Users\\steph\\Downloads\\EFFIS_All_Fires_Compiled_all.xlsx'\n",
    "\n",
    "# Read the Excel file\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Print all column names so you can identify the exact ones\n",
    "print(\"Columns in the file:\")\n",
    "print(df.columns.tolist())\n",
    "\n",
    "# UPDATE THESE WITH THE EXACT COLUMN NAMES FROM THE OUTPUT ABOVE\n",
    "lat_col = 'Lat'      # e.g., 'latitude', 'LAT', 'Latitude'\n",
    "lon_col = 'Lon'      # e.g., 'longitude', 'LON', 'Longitude'\n",
    "date_col = 'Date'    # e.g., 'date', 'FIRE_DATE', 'Date '\n",
    "\n",
    "# Extract only the three columns\n",
    "extracted_df = df[[lat_col, lon_col, date_col]].copy()\n",
    "\n",
    "# Drop rows with any missing values\n",
    "extracted_df = extracted_df.dropna()\n",
    "\n",
    "# Convert Date to proper datetime (handles various formats)\n",
    "extracted_df[date_col] = pd.to_datetime(extracted_df[date_col], errors='coerce')\n",
    "\n",
    "# No file output, no previews printed\n",
    "print(f\"Done! Loaded and cleaned {len(extracted_df)} rows into 'extracted_df'.\")\n",
    "print(\"You can now use the DataFrame in your script, e.g., extracted_df.head()\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7fadf5-cde2-4ade-bc8d-8e969c1e3f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "from PIL import Image as PILImage, ImageDraw, ImageFont\n",
    "\n",
    "# Configuration\n",
    "PREVIEW_DIR = r'C:\\Users\\steph\\Downloads\\master_thesis\\scripts\\sentinel2_fire_images\\preview'\n",
    "PROCESSED_DIR = os.path.join(PREVIEW_DIR, 'processed')\n",
    "\n",
    "# Create processed directory if it doesn't exist\n",
    "os.makedirs(PROCESSED_DIR, exist_ok=True)\n",
    "\n",
    "def extract_date_from_filename(filename):\n",
    "    \"\"\"Extract date from filename.\"\"\"\n",
    "    import re\n",
    "    date_match = re.search(r'(\\d{8})', filename)\n",
    "    if date_match:\n",
    "        date_str = date_match.group(1)\n",
    "        return f\"{date_str[:4]}-{date_str[4:6]}-{date_str[6:8]}\"\n",
    "    return \"Unknown Date\"\n",
    "\n",
    "def extract_image_type_from_filename(filename):\n",
    "    \"\"\"Extract image type (before/after) from filename.\"\"\"\n",
    "    if 'before' in filename.lower():\n",
    "        return \"Before Fire\"\n",
    "    elif 'after' in filename.lower():\n",
    "        return \"After Fire\"\n",
    "    return \"Unknown\"\n",
    "\n",
    "def extract_fire_id_from_filename(filename):\n",
    "    \"\"\"Extract fire ID from filename.\"\"\"\n",
    "    import re\n",
    "    # Look for patterns like _001_, _002_, etc.\n",
    "    fire_match = re.search(r'_(\\d{3})_', filename)\n",
    "    if fire_match:\n",
    "        return fire_match.group(1)\n",
    "    return \"Unknown\"\n",
    "\n",
    "def add_scale_bar_to_image(pil_image, resolution_m, scale_km=2):\n",
    "    \"\"\"Add a scale bar to the PIL image.\"\"\"\n",
    "    try:\n",
    "        # Create a copy to draw on\n",
    "        image_with_scale = pil_image.copy()\n",
    "        draw = ImageDraw.Draw(image_with_scale)\n",
    "        \n",
    "        # Calculate scale bar dimensions\n",
    "        scale_pixels = int((scale_km * 1000) / resolution_m)\n",
    "        \n",
    "        # Position in bottom right corner (5% from right, 5% from bottom)\n",
    "        width, height = image_with_scale.size\n",
    "        x_pos = width - int(width * 0.05) - scale_pixels\n",
    "        y_pos = height - int(height * 0.05)\n",
    "        \n",
    "        # Draw scale bar (white rectangle with black border)\n",
    "        bar_height = int(height * 0.01)  # 1% of image height\n",
    "        bar_width = scale_pixels\n",
    "        \n",
    "        # Draw the scale bar\n",
    "        draw.rectangle([x_pos, y_pos, x_pos + bar_width, y_pos - bar_height], \n",
    "                      fill='white', outline='black', width=2)\n",
    "        \n",
    "        # Add scale text\n",
    "        try:\n",
    "            # Try to use a font\n",
    "            font = ImageFont.load_default()\n",
    "            text = f\"{scale_km} km\"\n",
    "            text_width = draw.textlength(text, font=font)\n",
    "            text_x = x_pos + (bar_width - text_width) // 2\n",
    "            text_y = y_pos - bar_height - 20\n",
    "            \n",
    "            # Draw text background\n",
    "            padding = 4\n",
    "            draw.rectangle([text_x - padding, text_y - padding, \n",
    "                          text_x + text_width + padding, text_y + 12 + padding], \n",
    "                         fill='black')\n",
    "            \n",
    "            # Draw text\n",
    "            draw.text((text_x, text_y), text, fill='white', font=font)\n",
    "        except:\n",
    "            # Fallback without font\n",
    "            text_x = x_pos + bar_width // 2 - 10\n",
    "            text_y = y_pos - bar_height - 15\n",
    "            draw.rectangle([text_x - 15, text_y - 2, text_x + 25, text_y + 10], fill='black')\n",
    "            draw.text((text_x, text_y), f\"{scale_km} km\", fill='white')\n",
    "        \n",
    "        return image_with_scale\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  ‚ö† Could not add scale bar: {e}\")\n",
    "        return pil_image\n",
    "\n",
    "def find_image_files():\n",
    "    \"\"\"Find all TIFF files with before/after in the name.\"\"\"\n",
    "    if not os.path.exists(PREVIEW_DIR):\n",
    "        return [], []\n",
    "    \n",
    "    all_files = os.listdir(PREVIEW_DIR)\n",
    "    \n",
    "    # More flexible pattern matching\n",
    "    before_files = []\n",
    "    after_files = []\n",
    "    \n",
    "    for file in all_files:\n",
    "        if (file.endswith('.tif') or file.endswith('.tiff')) and 'square_10km' in file:\n",
    "            if 'before' in file.lower():\n",
    "                before_files.append(file)\n",
    "            elif 'after' in file.lower():\n",
    "                after_files.append(file)\n",
    "    \n",
    "    return before_files, after_files\n",
    "\n",
    "def get_rgb_bands(src):\n",
    "    \"\"\"Extract and return proper RGB bands in correct order.\"\"\"\n",
    "    print(f\"  - Available bands: {src.count}\")\n",
    "    \n",
    "    # Try to identify bands by their descriptions\n",
    "    band_descriptions = []\n",
    "    if src.descriptions:\n",
    "        band_descriptions = [desc for desc in src.descriptions]\n",
    "        print(f\"  - Band descriptions: {band_descriptions}\")\n",
    "    \n",
    "    # Look for specific band names in descriptions\n",
    "    red_band = None\n",
    "    green_band = None\n",
    "    blue_band = None\n",
    "    \n",
    "    for i, desc in enumerate(band_descriptions):\n",
    "        if desc and 'B04' in desc:\n",
    "            red_band = i + 1\n",
    "        elif desc and 'B03' in desc:\n",
    "            green_band = i + 1\n",
    "        elif desc and 'B02' in desc:\n",
    "            blue_band = i + 1\n",
    "    \n",
    "    # If we found all RGB bands by description\n",
    "    if red_band and green_band and blue_band:\n",
    "        print(f\"  - Using band descriptions:\")\n",
    "        print(f\"    Band {blue_band}: {band_descriptions[blue_band-1]} (Blue)\")\n",
    "        print(f\"    Band {green_band}: {band_descriptions[green_band-1]} (Green)\")\n",
    "        print(f\"    Band {red_band}: {band_descriptions[red_band-1]} (Red)\")\n",
    "        red = src.read(red_band)\n",
    "        green = src.read(green_band)\n",
    "        blue = src.read(blue_band)\n",
    "        return red, green, blue\n",
    "    \n",
    "    # Fallback: assume standard Sentinel-2 order\n",
    "    if src.count >= 4:\n",
    "        # Assume standard Sentinel-2 order: B01, B02, B03, B04, etc.\n",
    "        # So for RGB we need bands 2, 3, 4 (Blue, Green, Red)\n",
    "        blue_band = 2  # B02\n",
    "        green_band = 3  # B03\n",
    "        red_band = 4    # B04\n",
    "        \n",
    "        if src.count >= red_band:\n",
    "            red = src.read(red_band)\n",
    "            green = src.read(green_band)\n",
    "            blue = src.read(blue_band)\n",
    "            print(f\"  - Using standard Sentinel-2 band order:\")\n",
    "            print(f\"    Band {blue_band}: Blue (B02)\")\n",
    "            print(f\"    Band {green_band}: Green (B03)\")\n",
    "            print(f\"    Band {red_band}: Red (B04)\")\n",
    "            return red, green, blue\n",
    "    \n",
    "    # Fallback: try first 3 bands\n",
    "    if src.count >= 3:\n",
    "        print(\"  - Using first 3 bands as RGB\")\n",
    "        red = src.read(1)\n",
    "        green = src.read(2)\n",
    "        blue = src.read(3)\n",
    "        return red, green, blue\n",
    "    \n",
    "    # If only 1-2 bands, duplicate to create grayscale RGB\n",
    "    elif src.count >= 1:\n",
    "        print(\"  - Single band image, creating grayscale RGB\")\n",
    "        single_band = src.read(1)\n",
    "        return single_band, single_band, single_band\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(\"No bands found in image\")\n",
    "\n",
    "def enhance_rgb_contrast(red, green, blue):\n",
    "    \"\"\"Apply contrast enhancement to RGB bands individually.\"\"\"\n",
    "    def enhance_band(band):\n",
    "        # Use percentiles to avoid outliers\n",
    "        valid_pixels = band[band > 0]\n",
    "        if len(valid_pixels) > 0:\n",
    "            p2 = np.percentile(valid_pixels, 2)\n",
    "            p98 = np.percentile(valid_pixels, 98)\n",
    "            if p98 > p2:\n",
    "                enhanced = np.clip((band - p2) / (p98 - p2), 0, 1)\n",
    "                return (enhanced * 255).astype(np.uint8)\n",
    "        # Fallback: simple normalization\n",
    "        band_min = band.min()\n",
    "        band_max = band.max()\n",
    "        if band_max > band_min:\n",
    "            return ((band - band_min) / (band_max - band_min) * 255).astype(np.uint8)\n",
    "        else:\n",
    "            return band.astype(np.uint8)\n",
    "    \n",
    "    red_enhanced = enhance_band(red)\n",
    "    green_enhanced = enhance_band(green)\n",
    "    blue_enhanced = enhance_band(blue)\n",
    "    \n",
    "    return red_enhanced, green_enhanced, blue_enhanced\n",
    "\n",
    "def save_processed_image(pil_image, original_filename, suffix=\"\"):\n",
    "    \"\"\"Save processed image as PNG to the processed folder.\"\"\"\n",
    "    # Create new filename\n",
    "    base_name = os.path.splitext(original_filename)[0]\n",
    "    if suffix:\n",
    "        new_filename = f\"{base_name}_{suffix}.png\"\n",
    "    else:\n",
    "        new_filename = f\"{base_name}.png\"\n",
    "    \n",
    "    output_path = os.path.join(PROCESSED_DIR, new_filename)\n",
    "    pil_image.save(output_path, 'PNG')\n",
    "    print(f\"  üíæ Saved: {new_filename}\")\n",
    "    return output_path\n",
    "\n",
    "def display_all_images_with_messages():\n",
    "    \"\"\"Display all images with proper grouping and clear 'no image' messages.\"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"üåç DISPLAYING ALL FIRE IMAGES WITH SCALE BARS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Find all image files\n",
    "    before_files, after_files = find_image_files()\n",
    "    all_files = before_files + after_files\n",
    "    \n",
    "    if not all_files:\n",
    "        print(\"‚ùå No square_10km TIFF files found in the directory.\")\n",
    "        print(\"\\nüìÅ Available files in directory:\")\n",
    "        available_files = [f for f in os.listdir(PREVIEW_DIR) if f.endswith(('.tif', '.tiff'))]\n",
    "        if available_files:\n",
    "            for file in sorted(available_files):\n",
    "                print(f\"  - {file}\")\n",
    "        else:\n",
    "            print(\"  No TIFF files found.\")\n",
    "        return\n",
    "    \n",
    "    print(f\"üìä Found {len(before_files)} BEFORE and {len(after_files)} AFTER images\")\n",
    "    \n",
    "    # Group files by fire ID\n",
    "    fire_groups = {}\n",
    "    for img_file in all_files:\n",
    "        fire_id = extract_fire_id_from_filename(img_file)\n",
    "        if fire_id not in fire_groups:\n",
    "            fire_groups[fire_id] = {'before': [], 'after': []}\n",
    "        \n",
    "        if 'before' in img_file.lower():\n",
    "            fire_groups[fire_id]['before'].append(img_file)\n",
    "        elif 'after' in img_file.lower():\n",
    "            fire_groups[fire_id]['after'].append(img_file)\n",
    "    \n",
    "    # Display images grouped by fire ID\n",
    "    images_processed = 0\n",
    "    \n",
    "    for fire_id in sorted(fire_groups.keys()):\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"üî• FIRE LOCATION {fire_id}\")\n",
    "        print(f\"{'='*50}\")\n",
    "        \n",
    "        # Display before images for this fire\n",
    "        before_images = fire_groups[fire_id]['before']\n",
    "        if before_images:\n",
    "            print(f\"\\nüì∏ BEFORE FIRE IMAGES:\")\n",
    "            for img_file in sorted(before_images):\n",
    "                if process_and_display_image(img_file):\n",
    "                    images_processed += 1\n",
    "        else:\n",
    "            print(f\"\\n‚ùå No BEFORE images available for fire {fire_id}\")\n",
    "        \n",
    "        # Display after images for this fire\n",
    "        after_images = fire_groups[fire_id]['after']\n",
    "        if after_images:\n",
    "            print(f\"\\nüì∏ AFTER FIRE IMAGES:\")\n",
    "            for img_file in sorted(after_images):\n",
    "                if process_and_display_image(img_file):\n",
    "                    images_processed += 1\n",
    "        else:\n",
    "            print(f\"\\n‚ùå No AFTER images available for fire {fire_id}\")\n",
    "    \n",
    "    return images_processed\n",
    "\n",
    "def process_and_display_image(img_file):\n",
    "    \"\"\"Process and display a single image. Returns True if successful.\"\"\"\n",
    "    img_path = os.path.join(PREVIEW_DIR, img_file)\n",
    "    \n",
    "    display_type = extract_image_type_from_filename(img_file)\n",
    "    date_str = extract_date_from_filename(img_file)\n",
    "    fire_id = extract_fire_id_from_filename(img_file)\n",
    "    \n",
    "    try:\n",
    "        import rasterio\n",
    "        \n",
    "        with rasterio.open(img_path) as src:\n",
    "            print(f\"\\nüîÑ Processing: {img_file}\")\n",
    "            \n",
    "            # Get RGB bands\n",
    "            red, green, blue = get_rgb_bands(src)\n",
    "            \n",
    "            # Create enhanced RGB\n",
    "            red_enhanced, green_enhanced, blue_enhanced = enhance_rgb_contrast(red, green, blue)\n",
    "            rgb_enhanced = np.dstack((red_enhanced, green_enhanced, blue_enhanced))\n",
    "            \n",
    "            # Convert to PIL Image\n",
    "            enhanced_img = PILImage.fromarray(rgb_enhanced)\n",
    "            \n",
    "            # Add scale bar to ALL images\n",
    "            resolution_m = abs(src.transform[0])\n",
    "            enhanced_with_scale = add_scale_bar_to_image(enhanced_img, resolution_m, scale_km=2)\n",
    "            \n",
    "            # Save the processed image with scale\n",
    "            saved_path = save_processed_image(enhanced_with_scale, img_file, \"enhanced_scale\")\n",
    "            \n",
    "            # Display information and image\n",
    "            print(f\"üìä {display_type} - Fire {fire_id} - {date_str}\")\n",
    "            print(f\"üéØ Resolution: {resolution_m:.1f} meters/pixel\")\n",
    "            print(f\"üìè Scale bar: 2 km\")\n",
    "            print(f\"üñºÔ∏è  Image size: {enhanced_with_scale.size}\")\n",
    "            display(enhanced_with_scale)\n",
    "            print(f\"{'='*40}\")\n",
    "            return True\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error processing {img_file}: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return False\n",
    "\n",
    "def create_comparison_grid(before_images, after_images):\n",
    "    \"\"\"Create a comparison grid showing before/after pairs side by side.\"\"\"\n",
    "    if not before_images and not after_images:\n",
    "        return None\n",
    "    \n",
    "    print(f\"\\nüìä CREATING COMPARISON GRID\")\n",
    "    print(f\"   Before images: {len(before_images)}\")\n",
    "    print(f\"   After images: {len(after_images)}\")\n",
    "    \n",
    "    # This is a placeholder for grid creation functionality\n",
    "    # In a full implementation, you would resize images to same dimensions\n",
    "    # and create a matplotlib subplot grid\n",
    "    print(\"   üîß Grid comparison feature would be implemented here\")\n",
    "    return None\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to display and save processed RGB images.\"\"\"\n",
    "    print(\"üåç DISPLAYING ALL FIRE IMAGES WITH SCALE BARS\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"üìÅ Source directory: {PREVIEW_DIR}\")\n",
    "    print(f\"üíæ Output directory: {PROCESSED_DIR}\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"üìè Scale bars: 2 km (added to ALL images)\")\n",
    "    print(\"üé® Images: Enhanced contrast + Scale bars\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Check if directory exists\n",
    "    if not os.path.exists(PREVIEW_DIR):\n",
    "        print(f\"‚ùå Directory not found: {PREVIEW_DIR}\")\n",
    "        print(\"Please run the extraction script first to generate image files.\")\n",
    "        return\n",
    "    \n",
    "    # Display all images with proper messaging\n",
    "    images_processed = display_all_images_with_messages()\n",
    "    \n",
    "    # Print summary\n",
    "    before_files, after_files = find_image_files()\n",
    "    all_files = before_files + after_files\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"‚úÖ PROCESSING COMPLETED\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    if images_processed > 0:\n",
    "        print(f\"üìä Successfully processed {images_processed} images:\")\n",
    "        print(f\"   - {len(before_files)} BEFORE fire images\")\n",
    "        print(f\"   - {len(after_files)} AFTER fire images\")\n",
    "        print(f\"üìè Scale bars added to ALL images (2 km)\")\n",
    "        print(f\"üíæ All enhanced images with scale bars saved to: {PROCESSED_DIR}\")\n",
    "        \n",
    "        # List saved files\n",
    "        saved_files = [f for f in os.listdir(PROCESSED_DIR) if f.endswith('.png')]\n",
    "        if saved_files:\n",
    "            print(f\"\\nüìÅ Saved PNG files (with scale bars):\")\n",
    "            for file in sorted(saved_files):\n",
    "                print(f\"   - {file}\")\n",
    "                \n",
    "        # Show scale bar information\n",
    "        print(f\"\\nüìê Scale Bar Information:\")\n",
    "        print(f\"   - Length: 2 kilometers\")\n",
    "        print(f\"   - Position: Bottom-right corner\")\n",
    "        print(f\"   - Color: White bar with black border\")\n",
    "        print(f\"   - Text: White on black background\")\n",
    "        \n",
    "    else:\n",
    "        print(\"‚ùå No images were successfully processed.\")\n",
    "        print(\"üí° Please check that:\")\n",
    "        print(\"   - The extraction script has been run successfully\")\n",
    "        print(\"   - TIFF files exist in the preview directory\")\n",
    "        print(\"   - Files follow the naming pattern: square_10km_allbands_[before/after]_[fire_id]_[date].tif\")\n",
    "\n",
    "# Run the main function\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a82072-835c-43d0-9648-a04e883f85cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image as PILImage, ImageDraw\n",
    "import rasterio\n",
    "from IPython.display import display, HTML\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "# Configuration - UPDATED OUTPUT DIRECTORY\n",
    "PREVIEW_DIR = r'C:\\Users\\steph\\Downloads\\master_thesis\\scripts\\sentinel2_fire_images\\preview'\n",
    "CLASSIFIED_DIR = r'C:\\Users\\steph\\Downloads\\master_thesis\\scripts\\sentinel2_fire_images\\classification_results'\n",
    "os.makedirs(CLASSIFIED_DIR, exist_ok=True)\n",
    "\n",
    "# Land cover class definitions\n",
    "CLASSES = {\n",
    "    1: {'name': 'Fields/Agriculture', 'color': (255, 255, 100)},\n",
    "    2: {'name': 'Coniferous Forest', 'color': (0, 100, 0)},\n",
    "    3: {'name': 'Deciduous Forest', 'color': (50, 205, 50)},\n",
    "    4: {'name': 'Urban/Bare Soil', 'color': (169, 169, 169)}\n",
    "}\n",
    "\n",
    "def add_scale_bar_to_plot(ax, transform, scale_km=2):\n",
    "    \"\"\"Add a scale bar to matplotlib plot.\"\"\"\n",
    "    try:\n",
    "        # Get image dimensions in data coordinates\n",
    "        xlim = ax.get_xlim()\n",
    "        ylim = ax.get_ylim()\n",
    "        \n",
    "        # Calculate pixel size in meters using the transform\n",
    "        pixel_size_m = abs(transform[0])  # meters per pixel\n",
    "        \n",
    "        # Calculate scale bar length in pixels\n",
    "        scale_length_pixels = (scale_km * 1000) / pixel_size_m\n",
    "        \n",
    "        # Position in bottom right corner (5% from right, 5% from bottom)\n",
    "        x_range = xlim[1] - xlim[0]\n",
    "        y_range = ylim[1] - ylim[0]\n",
    "        \n",
    "        x_pos = xlim[1] - x_range * 0.05 - scale_length_pixels\n",
    "        y_pos = ylim[0] + y_range * 0.05\n",
    "        \n",
    "        # Draw scale bar\n",
    "        rect = plt.Rectangle((x_pos, y_pos), scale_length_pixels, y_range * 0.005,\n",
    "                           facecolor='white', edgecolor='black', linewidth=2)\n",
    "        ax.add_patch(rect)\n",
    "        \n",
    "        # Add scale text\n",
    "        ax.text(x_pos + scale_length_pixels / 2, y_pos - y_range * 0.02,\n",
    "               f'{scale_km} km', ha='center', va='top', color='white', \n",
    "               fontweight='bold', fontsize=10,\n",
    "               bbox=dict(boxstyle=\"round,pad=0.3\", facecolor='black', alpha=0.7))\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  ‚ö† Could not add scale bar to plot: {e}\")\n",
    "\n",
    "def identify_sentinel2_bands_correctly(bands):\n",
    "    \"\"\"Correctly identify Sentinel-2 bands - FIXED VERSION\"\"\"\n",
    "    print(f\"  - Number of bands: {len(bands)}\")\n",
    "    \n",
    "    band_info = {}\n",
    "    \n",
    "    if len(bands) >= 12:\n",
    "        # Standard 12-band Sentinel-2\n",
    "        band_info = {\n",
    "            'blue': bands[1],   # Band 2 - B02\n",
    "            'green': bands[2],  # Band 3 - B03\n",
    "            'red': bands[3],    # Band 4 - B04\n",
    "            'nir': bands[7]     # Band 8 - B08\n",
    "        }\n",
    "        print(\"  - Identified as 12-band Sentinel-2 (using B2, B3, B4, B8)\")\n",
    "        \n",
    "    elif len(bands) >= 4:\n",
    "        # Try to identify by wavelength characteristics\n",
    "        band_means = [np.mean(band) for band in bands[:4]]\n",
    "        \n",
    "        # NIR usually has highest reflectance in vegetation areas\n",
    "        # Red usually has lower reflectance\n",
    "        nir_idx = np.argmax(band_means)\n",
    "        red_idx = np.argmin(band_means[:3])  # Red is usually in first 3 bands\n",
    "        \n",
    "        remaining = [i for i in range(4) if i not in [nir_idx, red_idx]]\n",
    "        blue_idx = remaining[0]\n",
    "        green_idx = remaining[1]\n",
    "        \n",
    "        band_info = {\n",
    "            'blue': bands[blue_idx],\n",
    "            'green': bands[green_idx],\n",
    "            'red': bands[red_idx],\n",
    "            'nir': bands[nir_idx]\n",
    "        }\n",
    "        print(f\"  - Identified by reflectance: B{blue_idx+1}=Blue, B{green_idx+1}=Green, B{red_idx+1}=Red, B{nir_idx+1}=NIR\")\n",
    "        \n",
    "    else:\n",
    "        # Fallback - assume standard order\n",
    "        band_info = {\n",
    "            'blue': bands[0] if len(bands) > 0 else None,\n",
    "            'green': bands[1] if len(bands) > 1 else None,\n",
    "            'red': bands[2] if len(bands) > 2 else None,\n",
    "            'nir': bands[3] if len(bands) > 3 else None\n",
    "        }\n",
    "        print(\"  - Using standard band order assumption\")\n",
    "    \n",
    "    return band_info\n",
    "\n",
    "def calculate_ndvi_safe(red, nir):\n",
    "    \"\"\"Calculate NDVI with safety checks and normalization.\"\"\"\n",
    "    # Ensure we're working with float arrays\n",
    "    red = red.astype(np.float32)\n",
    "    nir = nir.astype(np.float32)\n",
    "    \n",
    "    # Handle division by zero\n",
    "    denominator = nir + red\n",
    "    valid_mask = denominator > 0\n",
    "    \n",
    "    ndvi = np.zeros_like(red, dtype=np.float32)\n",
    "    ndvi[valid_mask] = (nir[valid_mask] - red[valid_mask]) / denominator[valid_mask]\n",
    "    \n",
    "    # NDVI should be between -1 and 1\n",
    "    ndvi = np.clip(ndvi, -1, 1)\n",
    "    \n",
    "    return ndvi\n",
    "\n",
    "def classify_with_corrected_ndvi(band_info):\n",
    "    \"\"\"Classification with CORRECTED NDVI thresholds.\"\"\"\n",
    "    red = band_info.get('red')\n",
    "    nir = band_info.get('nir')\n",
    "    \n",
    "    if red is None or nir is None:\n",
    "        print(\"‚ùå Missing Red or NIR bands for classification\")\n",
    "        return np.zeros(red.shape, dtype=np.uint8), np.zeros(red.shape)\n",
    "    \n",
    "    print(f\"  - Red band range: [{red.min():.1f}, {red.max():.1f}]\")\n",
    "    print(f\"  - NIR band range: [{nir.min():.1f}, {nir.max():.1f}]\")\n",
    "    \n",
    "    # Calculate proper NDVI\n",
    "    ndvi = calculate_ndvi_safe(red, nir)\n",
    "    \n",
    "    print(f\"  - NDVI range: [{ndvi.min():.3f}, {ndvi.max():.3f}]\")\n",
    "    print(f\"  - NDVI mean: {ndvi.mean():.3f}\")\n",
    "    \n",
    "    # Initialize classification\n",
    "    classification = np.ones(red.shape, dtype=np.uint8)  # Default to Fields\n",
    "    \n",
    "    # CORRECTED NDVI-BASED CLASSIFICATION\n",
    "    # Based on your feedback: 0.1-0.3 for fields, over 0.3 for forest\n",
    "    urban_mask = ndvi < 0.1\n",
    "    fields_mask = (ndvi >= 0.1) & (ndvi < 0.3)  # FIELDS: 0.1 to 0.3\n",
    "    forest_mask = ndvi >= 0.3                   # FORESTS: ‚â• 0.3\n",
    "    \n",
    "    # Within forests, distinguish coniferous vs deciduous\n",
    "    if np.any(forest_mask):\n",
    "        # Use NIR/Red ratio to distinguish forest types\n",
    "        nir_red_ratio = np.where(red == 0, 1, nir / red)\n",
    "        \n",
    "        # Coniferous typically has lower NIR/Red ratio\n",
    "        coniferous_mask = forest_mask & (nir_red_ratio < 3.0)\n",
    "        deciduous_mask = forest_mask & (nir_red_ratio >= 3.0)\n",
    "    else:\n",
    "        coniferous_mask = np.zeros_like(forest_mask)\n",
    "        deciduous_mask = np.zeros_like(forest_mask)\n",
    "    \n",
    "    # Apply classifications\n",
    "    classification[urban_mask] = 4          # Urban/Bare Soil\n",
    "    classification[coniferous_mask] = 2     # Coniferous Forest\n",
    "    classification[deciduous_mask] = 3      # Deciduous Forest\n",
    "    classification[fields_mask] = 1         # Fields/Agriculture\n",
    "    \n",
    "    # Print classification statistics for verification\n",
    "    print(f\"  - Classification preview:\")\n",
    "    print(f\"    Urban/Bare Soil: {np.sum(urban_mask):,} pixels ({np.sum(urban_mask)/urban_mask.size*100:.1f}%)\")\n",
    "    print(f\"    Fields/Agriculture: {np.sum(fields_mask):,} pixels ({np.sum(fields_mask)/fields_mask.size*100:.1f}%)\")\n",
    "    print(f\"    Forests: {np.sum(forest_mask):,} pixels ({np.sum(forest_mask)/forest_mask.size*100:.1f}%)\")\n",
    "    print(f\"    - Coniferous: {np.sum(coniferous_mask):,} pixels\")\n",
    "    print(f\"    - Deciduous: {np.sum(deciduous_mask):,} pixels\")\n",
    "    \n",
    "    return classification, ndvi\n",
    "\n",
    "def create_true_color_rgb(band_info):\n",
    "    \"\"\"Create TRUE COLOR RGB (Red, Green, Blue bands).\"\"\"\n",
    "    red = band_info.get('red')\n",
    "    green = band_info.get('green')\n",
    "    blue = band_info.get('blue')\n",
    "    \n",
    "    if red is not None and green is not None and blue is not None:\n",
    "        def enhance_band(band):\n",
    "            # Use percentiles to avoid outliers\n",
    "            p2 = np.percentile(band, 2)\n",
    "            p98 = np.percentile(band, 98)\n",
    "            enhanced = np.clip((band - p2) / (p98 - p2), 0, 1)\n",
    "            return (enhanced * 255).astype(np.uint8)\n",
    "        \n",
    "        red_enhanced = enhance_band(red)\n",
    "        green_enhanced = enhance_band(green)\n",
    "        blue_enhanced = enhance_band(blue)\n",
    "        \n",
    "        # TRUE COLOR: Red, Green, Blue\n",
    "        return np.dstack((red_enhanced, green_enhanced, blue_enhanced))\n",
    "    else:\n",
    "        print(\"‚ùå Missing bands for true color RGB\")\n",
    "        return None\n",
    "\n",
    "def create_false_color_rgb(band_info):\n",
    "    \"\"\"Create FALSE COLOR RGB (NIR, Red, Green bands).\"\"\"\n",
    "    nir = band_info.get('nir')\n",
    "    red = band_info.get('red')\n",
    "    green = band_info.get('green')\n",
    "    \n",
    "    if nir is not None and red is not None and green is not None:\n",
    "        def enhance_band(band):\n",
    "            p2 = np.percentile(band, 2)\n",
    "            p98 = np.percentile(band, 98)\n",
    "            enhanced = np.clip((band - p2) / (p98 - p2), 0, 1)\n",
    "            return (enhanced * 255).astype(np.uint8)\n",
    "        \n",
    "        nir_enhanced = enhance_band(nir)\n",
    "        red_enhanced = enhance_band(red)\n",
    "        green_enhanced = enhance_band(green)\n",
    "        \n",
    "        # FALSE COLOR: NIR as Red, Red as Green, Green as Blue\n",
    "        return np.dstack((nir_enhanced, red_enhanced, green_enhanced))\n",
    "    else:\n",
    "        print(\"‚ùå Missing bands for false color RGB\")\n",
    "        return None\n",
    "\n",
    "def create_ndvi_colormap(ndvi):\n",
    "    \"\"\"Create a colored NDVI visualization.\"\"\"\n",
    "    # Normalize NDVI from -1 to 1 to 0 to 1\n",
    "    ndvi_normalized = (ndvi + 1) / 2\n",
    "    ndvi_normalized = np.clip(ndvi_normalized, 0, 1)\n",
    "    \n",
    "    # Use RdYlGn colormap (Red-Yellow-Green)\n",
    "    cmap = plt.cm.RdYlGn\n",
    "    ndvi_colored = (cmap(ndvi_normalized) * 255).astype(np.uint8)[:, :, :3]  # Remove alpha channel\n",
    "    return ndvi_colored\n",
    "\n",
    "def create_classification_colormap(classification):\n",
    "    \"\"\"Create a colored classification visualization.\"\"\"\n",
    "    height, width = classification.shape\n",
    "    class_rgb = np.zeros((height, width, 3), dtype=np.uint8)\n",
    "    for class_id, class_info in CLASSES.items():\n",
    "        mask = classification == class_id\n",
    "        class_rgb[mask] = class_info['color']\n",
    "    return class_rgb\n",
    "\n",
    "def create_comprehensive_dashboard(true_color, false_color, classification, stats, ndvi, img_file, image_type, transform):\n",
    "    \"\"\"Create a comprehensive dashboard figure with scale bars.\"\"\"\n",
    "    # Create visualizations\n",
    "    ndvi_vis = create_ndvi_colormap(ndvi)\n",
    "    class_vis = create_classification_colormap(classification)\n",
    "    \n",
    "    # Create figure with subplots\n",
    "    fig = plt.figure(figsize=(20, 12))\n",
    "    fig.suptitle(f'{image_type.upper()} FIRE - Land Cover Classification - {img_file}', \n",
    "                 fontsize=18, fontweight='bold', y=0.98)\n",
    "    \n",
    "    # Create grid layout\n",
    "    gs = fig.add_gridspec(2, 3, hspace=0.3, wspace=0.3)\n",
    "    \n",
    "    # Plot 1: TRUE COLOR RGB (Red, Green, Blue)\n",
    "    ax1 = fig.add_subplot(gs[0, 0])\n",
    "    if true_color is not None:\n",
    "        ax1.imshow(true_color)\n",
    "        add_scale_bar_to_plot(ax1, transform)\n",
    "    ax1.set_title('TRUE COLOR (Red, Green, Blue)', fontsize=12, fontweight='bold')\n",
    "    ax1.axis('off')\n",
    "    \n",
    "    # Plot 2: FALSE COLOR (NIR, Red, Green)\n",
    "    ax2 = fig.add_subplot(gs[0, 1])\n",
    "    if false_color is not None:\n",
    "        ax2.imshow(false_color)\n",
    "        add_scale_bar_to_plot(ax2, transform)\n",
    "    ax2.set_title('FALSE COLOR (NIR, Red, Green)', fontsize=12, fontweight='bold')\n",
    "    ax2.axis('off')\n",
    "    \n",
    "    # Plot 3: NDVI Visualization\n",
    "    ax3 = fig.add_subplot(gs[0, 2])\n",
    "    ax3.imshow(ndvi_vis)\n",
    "    add_scale_bar_to_plot(ax3, transform)\n",
    "    ax3.set_title('NDVI Map (Red=Low, Green=High Vegetation)', fontsize=12, fontweight='bold')\n",
    "    ax3.axis('off')\n",
    "    \n",
    "    # Plot 4: Classification Map\n",
    "    ax4 = fig.add_subplot(gs[1, 0])\n",
    "    ax4.imshow(class_vis)\n",
    "    add_scale_bar_to_plot(ax4, transform)\n",
    "    ax4.set_title('Land Cover Classification', fontsize=12, fontweight='bold')\n",
    "    ax4.axis('off')\n",
    "    \n",
    "    # Plot 5: Classification Statistics\n",
    "    ax5 = fig.add_subplot(gs[1, 1])\n",
    "    classes = [CLASSES[class_id]['name'] for class_id in sorted(stats.keys())]\n",
    "    percentages = [stats[class_id]['percentage'] for class_id in sorted(stats.keys())]\n",
    "    colors = [tuple(c/255 for c in CLASSES[class_id]['color']) for class_id in sorted(stats.keys())]\n",
    "    \n",
    "    bars = ax5.bar(classes, percentages, color=colors, edgecolor='black', alpha=0.7)\n",
    "    ax5.set_title('Land Cover Distribution (%)', fontsize=12, fontweight='bold')\n",
    "    ax5.set_ylabel('Percentage (%)')\n",
    "    ax5.tick_params(axis='x', rotation=45)\n",
    "    ax5.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for bar, percentage in zip(bars, percentages):\n",
    "        height = bar.get_height()\n",
    "        ax5.text(bar.get_x() + bar.get_width()/2., height + 0.5,\n",
    "                f'{percentage:.1f}%', ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    # Plot 6: Text summary\n",
    "    ax6 = fig.add_subplot(gs[1, 2])\n",
    "    ax6.axis('off')\n",
    "    \n",
    "    # Calculate summary statistics\n",
    "    vegetation_classes = [1, 2, 3]\n",
    "    total_vegetation = sum(stats[c]['pixels'] for c in vegetation_classes)\n",
    "    total_vegetation_pct = (total_vegetation / classification.size) * 100\n",
    "    \n",
    "    # NDVI distribution\n",
    "    ndvi_urban = np.sum(ndvi < 0.1) / ndvi.size * 100\n",
    "    ndvi_fields = np.sum((ndvi >= 0.1) & (ndvi < 0.3)) / ndvi.size * 100\n",
    "    ndvi_forest = np.sum(ndvi >= 0.3) / ndvi.size * 100\n",
    "    \n",
    "    summary_text = [\n",
    "        \"LAND COVER SUMMARY:\",\n",
    "        f\"Total Vegetation: {total_vegetation_pct:.1f}%\",\n",
    "        f\"Forests: {stats[2]['percentage'] + stats[3]['percentage']:.1f}%\",\n",
    "        f\"Fields: {stats[1]['percentage']:.1f}%\",\n",
    "        f\"Urban/Bare Soil: {stats[4]['percentage']:.1f}%\",\n",
    "        \"\",\n",
    "        \"NDVI DISTRIBUTION:\",\n",
    "        f\"NDVI < 0.1 (Urban): {ndvi_urban:.1f}%\",\n",
    "        f\"NDVI 0.1-0.3 (Fields): {ndvi_fields:.1f}%\",\n",
    "        f\"NDVI ‚â• 0.3 (Forests): {ndvi_forest:.1f}%\",\n",
    "        f\"NDVI Range: [{ndvi.min():.3f}, {ndvi.max():.3f}]\",\n",
    "        \"\",\n",
    "        \"SCALE INFORMATION:\",\n",
    "        f\"Scale bars: 2 km (all images)\",\n",
    "        f\"Resolution: {abs(transform[0]):.1f} m/pixel\"\n",
    "    ]\n",
    "    \n",
    "    ax6.text(0.02, 0.95, \"\\n\".join(summary_text), transform=ax6.transAxes, \n",
    "             fontsize=11, verticalalignment='top', fontfamily='monospace',\n",
    "             bbox=dict(boxstyle=\"round,pad=0.5\", facecolor=\"lightgray\", alpha=0.7))\n",
    "    \n",
    "    return fig\n",
    "\n",
    "def save_dashboard_as_png(true_color, false_color, classification, stats, ndvi, img_file, image_type, output_dir, transform):\n",
    "    \"\"\"Save only the dashboard as PNG.\"\"\"\n",
    "    base_name = os.path.splitext(img_file)[0]\n",
    "    \n",
    "    # Create and save comprehensive dashboard\n",
    "    fig = create_comprehensive_dashboard(true_color, false_color, classification, stats, ndvi, img_file, image_type, transform)\n",
    "    dashboard_path = os.path.join(output_dir, f\"{base_name}_dashboard.png\")\n",
    "    fig.savefig(dashboard_path, dpi=300, bbox_inches='tight', facecolor='white')\n",
    "    plt.close(fig)\n",
    "    \n",
    "    print(f\"üíæ Dashboard saved as: {dashboard_path}\")\n",
    "    return dashboard_path\n",
    "\n",
    "def display_corrected_results(true_color, false_color, classification, stats, ndvi, img_file, image_type, transform):\n",
    "    \"\"\"Display results with CORRECTED NDVI thresholds and save dashboard.\"\"\"\n",
    "    # Create classification image\n",
    "    class_rgb = create_classification_colormap(classification)\n",
    "    \n",
    "    # Display header with image type\n",
    "    display(HTML(f\"<h2>üåç {image_type.upper()} FIRE - {img_file}</h2>\"))\n",
    "    \n",
    "    # Create and display the dashboard\n",
    "    fig = create_comprehensive_dashboard(true_color, false_color, classification, stats, ndvi, img_file, image_type, transform)\n",
    "    plt.show()\n",
    "    \n",
    "    # Save only dashboard as PNG\n",
    "    dashboard_path = save_dashboard_as_png(true_color, false_color, classification, stats, ndvi, img_file, image_type, CLASSIFIED_DIR, transform)\n",
    "    \n",
    "    # Display statistics in console WITH EMOJIS\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(f\"üìä {image_type.upper()} FIRE - CLASSIFICATION STATISTICS\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Sort by percentage (descending)\n",
    "    sorted_stats = sorted(stats.items(), key=lambda x: x[1]['percentage'], reverse=True)\n",
    "    \n",
    "    for class_id, stat in sorted_stats:\n",
    "        print(f\"üè∑Ô∏è  {stat['name']:20} {stat['percentage']:6.2f}% ({stat['pixels']:>8,} pixels)\")\n",
    "    \n",
    "    # Vegetation analysis\n",
    "    vegetation_classes = [1, 2, 3]\n",
    "    total_vegetation = sum(stats[c]['pixels'] for c in vegetation_classes)\n",
    "    total_vegetation_pct = (total_vegetation / classification.size) * 100\n",
    "    \n",
    "    print(f\"\\nüåø VEGETATION ANALYSIS:\")\n",
    "    print(f\"   Total Vegetation: {total_vegetation_pct:.1f}%\")\n",
    "    print(f\"   Forests: {stats[2]['percentage'] + stats[3]['percentage']:.1f}%\")\n",
    "    print(f\"   Fields: {stats[1]['percentage']:.1f}%\")\n",
    "    print(f\"   Urban/Bare Soil: {stats[4]['percentage']:.1f}%\")\n",
    "    \n",
    "    # CORRECTED NDVI distribution\n",
    "    print(f\"\\nüéØ CORRECTED NDVI DISTRIBUTION:\")\n",
    "    ndvi_urban = np.sum(ndvi < 0.1) / ndvi.size * 100\n",
    "    ndvi_fields = np.sum((ndvi >= 0.1) & (ndvi < 0.3)) / ndvi.size * 100  # FIELDS: 0.1-0.3\n",
    "    ndvi_forest = np.sum(ndvi >= 0.3) / ndvi.size * 100                   # FORESTS: ‚â•0.3\n",
    "    \n",
    "    print(f\"   NDVI < 0.1 (Urban):        {ndvi_urban:.1f}%\")\n",
    "    print(f\"   NDVI 0.1-0.3 (Fields):     {ndvi_fields:.1f}%\")\n",
    "    print(f\"   NDVI ‚â• 0.3 (Forests):      {ndvi_forest:.1f}%\")\n",
    "    print(f\"   NDVI Range: [{ndvi.min():.3f}, {ndvi.max():.3f}]\")\n",
    "    \n",
    "    # Scale information\n",
    "    print(f\"\\nüìè SCALE INFORMATION:\")\n",
    "    print(f\"   Scale bars: 2 km (added to all images)\")\n",
    "    print(f\"   Resolution: {abs(transform[0]):.1f} meters/pixel\")\n",
    "    \n",
    "    # Verify classification matches NDVI distribution\n",
    "    print(f\"\\n‚úÖ VERIFICATION:\")\n",
    "    print(f\"   Fields classification:    {stats[1]['percentage']:.1f}%\")\n",
    "    print(f\"   Fields from NDVI:         {ndvi_fields:.1f}%\")\n",
    "    print(f\"   Forests classification:   {(stats[2]['percentage'] + stats[3]['percentage']):.1f}%\")\n",
    "    print(f\"   Forests from NDVI:        {ndvi_forest:.1f}%\")\n",
    "    \n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    return stats, dashboard_path\n",
    "\n",
    "def process_image_corrected(img_file, image_type):\n",
    "    \"\"\"Process image with CORRECTED NDVI thresholds.\"\"\"\n",
    "    img_path = os.path.join(PREVIEW_DIR, img_file)\n",
    "    \n",
    "    try:\n",
    "        with rasterio.open(img_path) as src:\n",
    "            print(f\"\\nüîÑ PROCESSING {image_type.upper()} FIRE: {img_file}\")\n",
    "            print(f\"  - Image shape: {src.shape}\")\n",
    "            print(f\"  - Number of bands: {src.count}\")\n",
    "            print(f\"  - Data type: {src.dtypes[0]}\")\n",
    "            print(f\"  - Resolution: {abs(src.transform[0]):.1f} m/pixel\")\n",
    "            \n",
    "            # Read all bands\n",
    "            bands = []\n",
    "            for i in range(1, src.count + 1):\n",
    "                band_data = src.read(i)\n",
    "                print(f\"  - Band {i}: range [{band_data.min():.1f}, {band_data.max():.1f}]\")\n",
    "                bands.append(band_data)\n",
    "            \n",
    "            # Correct band identification\n",
    "            band_info = identify_sentinel2_bands_correctly(bands)\n",
    "            \n",
    "            # CORRECTED classification with proper NDVI thresholds\n",
    "            classification, ndvi = classify_with_corrected_ndvi(band_info)\n",
    "            \n",
    "            # Calculate statistics\n",
    "            total_pixels = classification.size\n",
    "            stats = {}\n",
    "            for class_id, class_info in CLASSES.items():\n",
    "                class_pixels = np.sum(classification == class_id)\n",
    "                stats[class_id] = {\n",
    "                    'name': class_info['name'],\n",
    "                    'percentage': (class_pixels / total_pixels) * 100,\n",
    "                    'pixels': class_pixels\n",
    "                }\n",
    "            \n",
    "            # Create CORRECT visualizations\n",
    "            true_color = create_true_color_rgb(band_info)   # Red, Green, Blue\n",
    "            false_color = create_false_color_rgb(band_info) # NIR, Red, Green\n",
    "            \n",
    "            # Display corrected results and save dashboard\n",
    "            stats, dashboard_path = display_corrected_results(true_color, false_color, classification, stats, ndvi, img_file, image_type, src.transform)\n",
    "            \n",
    "            return classification, stats, dashboard_path\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error processing {img_file}: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None, None, None\n",
    "\n",
    "def find_and_group_image_files():\n",
    "    \"\"\"Find all image files and group them by fire ID.\"\"\"\n",
    "    if not os.path.exists(PREVIEW_DIR):\n",
    "        return {}, {}\n",
    "    \n",
    "    all_files = [f for f in os.listdir(PREVIEW_DIR) \n",
    "                if f.endswith(('.tif', '.tiff')) and 'square_10km' in f]\n",
    "    \n",
    "    # Group files by fire ID\n",
    "    fire_groups = {}\n",
    "    for file in all_files:\n",
    "        # Extract fire ID from filename (e.g., square_10km_allbands_before_001_20231015.tif)\n",
    "        import re\n",
    "        fire_match = re.search(r'_(\\d{3})_', file)\n",
    "        if fire_match:\n",
    "            fire_id = fire_match.group(1)\n",
    "            if fire_id not in fire_groups:\n",
    "                fire_groups[fire_id] = {'before': [], 'after': []}\n",
    "            \n",
    "            if 'before' in file.lower():\n",
    "                fire_groups[fire_id]['before'].append(file)\n",
    "            elif 'after' in file.lower():\n",
    "                fire_groups[fire_id]['after'].append(file)\n",
    "    \n",
    "    return all_files, fire_groups\n",
    "\n",
    "def display_all_images_with_messages():\n",
    "    \"\"\"Display all images with proper grouping and clear 'no image' messages.\"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üåç DISPLAYING ALL FIRE CLASSIFICATION RESULTS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Find and group all image files\n",
    "    all_files, fire_groups = find_and_group_image_files()\n",
    "    \n",
    "    if not all_files:\n",
    "        print(\"‚ùå No square_10km TIFF files found in the directory.\")\n",
    "        print(\"\\nüìÅ Available files in directory:\")\n",
    "        available_files = [f for f in os.listdir(PREVIEW_DIR) if f.endswith(('.tif', '.tiff'))]\n",
    "        if available_files:\n",
    "            for file in sorted(available_files):\n",
    "                print(f\"  - {file}\")\n",
    "        else:\n",
    "            print(\"  No TIFF files found.\")\n",
    "        return 0\n",
    "    \n",
    "    print(f\"üìä Found {len(all_files)} total images across {len(fire_groups)} fire locations\")\n",
    "    \n",
    "    # Store results for comparison\n",
    "    results = {}\n",
    "    images_processed = 0\n",
    "    \n",
    "    # Process each fire location\n",
    "    for fire_id in sorted(fire_groups.keys()):\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"üî• FIRE LOCATION {fire_id}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        # Process before images for this fire\n",
    "        before_images = fire_groups[fire_id]['before']\n",
    "        if before_images:\n",
    "            print(f\"\\nüü¢ PROCESSING BEFORE FIRE IMAGES:\")\n",
    "            for img_file in sorted(before_images):\n",
    "                classification, stats, dashboard_path = process_image_corrected(img_file, \"BEFORE\")\n",
    "                if stats:\n",
    "                    results[img_file] = {'stats': stats, 'type': 'before', 'dashboard': dashboard_path}\n",
    "                    images_processed += 1\n",
    "        else:\n",
    "            print(f\"\\n‚ùå No BEFORE images available for fire {fire_id}\")\n",
    "        \n",
    "        # Process after images for this fire\n",
    "        after_images = fire_groups[fire_id]['after']\n",
    "        if after_images:\n",
    "            print(f\"\\nüî¥ PROCESSING AFTER FIRE IMAGES:\")\n",
    "            for img_file in sorted(after_images):\n",
    "                classification, stats, dashboard_path = process_image_corrected(img_file, \"AFTER\")\n",
    "                if stats:\n",
    "                    results[img_file] = {'stats': stats, 'type': 'after', 'dashboard': dashboard_path}\n",
    "                    images_processed += 1\n",
    "        else:\n",
    "            print(f\"\\n‚ùå No AFTER images available for fire {fire_id}\")\n",
    "    \n",
    "    return images_processed, results\n",
    "\n",
    "def compare_before_after(before_stats, after_stats, before_file, after_file):\n",
    "    \"\"\"Display comparison between before and after fire images.\"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üî• FIRE IMPACT ANALYSIS - BEFORE vs AFTER\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    print(f\"\\nüìà CHANGE ANALYSIS:\")\n",
    "    print(\"-\" * 70)\n",
    "    print(f\"{'Land Cover Type':20} {'Before %':>10} {'After %':>10} {'Change %':>12} {'Area Change':>15}\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    for class_id in sorted(CLASSES.keys()):\n",
    "        class_name = CLASSES[class_id]['name']\n",
    "        before_pct = before_stats[class_id]['percentage']\n",
    "        after_pct = after_stats[class_id]['percentage']\n",
    "        change_pct = after_pct - before_pct\n",
    "        area_change = after_stats[class_id]['pixels'] - before_stats[class_id]['pixels']\n",
    "        \n",
    "        change_symbol = \"‚Üë\" if change_pct > 0.1 else \"‚Üì\" if change_pct < -0.1 else \"‚âà\"\n",
    "        \n",
    "        print(f\"{class_name:20} {before_pct:>9.2f}% {after_pct:>9.2f}% {change_pct:>+11.2f}% {area_change:>+13,} px {change_symbol}\")\n",
    "    \n",
    "    # Forest impact analysis\n",
    "    before_forest = before_stats[2]['percentage'] + before_stats[3]['percentage']\n",
    "    after_forest = after_stats[2]['percentage'] + after_stats[3]['percentage']\n",
    "    forest_change = after_forest - before_forest\n",
    "    \n",
    "    before_vegetation = before_stats[1]['percentage'] + before_forest\n",
    "    after_vegetation = after_stats[1]['percentage'] + after_forest\n",
    "    vegetation_change = after_vegetation - before_vegetation\n",
    "    \n",
    "    print(f\"\\nüå≤ FIRE IMPACT SUMMARY:\")\n",
    "    print(f\"   Total Forest Cover Change: {forest_change:+.2f}%\")\n",
    "    print(f\"   Total Vegetation Change: {vegetation_change:+.2f}%\")\n",
    "    \n",
    "    if forest_change < -5:\n",
    "        print(\"   üö® SIGNIFICANT FOREST LOSS DETECTED\")\n",
    "    elif forest_change < -1:\n",
    "        print(\"   ‚ö†Ô∏è  MODERATE FOREST LOSS DETECTED\")\n",
    "    elif forest_change > 1:\n",
    "        print(\"   üå± FOREST GROWTH DETECTED\")\n",
    "    else:\n",
    "        print(\"   ‚úÖ MINIMAL FOREST CHANGE\")\n",
    "    \n",
    "    if vegetation_change < -5:\n",
    "        print(\"   üö® SIGNIFICANT VEGETATION LOSS DETECTED\")\n",
    "    elif vegetation_change < -1:\n",
    "        print(\"   ‚ö†Ô∏è  MODERATE VEGETATION LOSS DETECTED\")\n",
    "    else:\n",
    "        print(\"   ‚úÖ MINIMAL VEGETATION CHANGE\")\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "\n",
    "def main_corrected():\n",
    "    \"\"\"Main function with CORRECTED NDVI thresholds and complete looping.\"\"\"\n",
    "    print(\"‚úÖ üåç CORRECTED SENTINEL-2 CLASSIFICATION - BEFORE & AFTER FIRE\")\n",
    "    print(\"=\" * 80)\n",
    "    print(\"üéØ CORRECTED NDVI THRESHOLDS:\")\n",
    "    print(\"   - Fields/Agriculture: NDVI 0.1 to 0.3\")\n",
    "    print(\"   - Forests: NDVI ‚â• 0.3\")\n",
    "    print(\"   - Urban/Bare Soil: NDVI < 0.1\")\n",
    "    print(\"üìè SCALE BARS: 2 km (added to ALL images)\")\n",
    "    print(f\"üíæ RESULTS SAVED TO: {CLASSIFIED_DIR}\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    if not os.path.exists(PREVIEW_DIR):\n",
    "        print(f\"‚ùå Directory not found: {PREVIEW_DIR}\")\n",
    "        print(\"Please run the extraction script first to generate image files.\")\n",
    "        return\n",
    "    \n",
    "    # Display all images with proper messaging\n",
    "    images_processed, results = display_all_images_with_messages()\n",
    "    \n",
    "    # Print summary\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"‚úÖ PROCESSING COMPLETED\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    if images_processed > 0:\n",
    "        print(f\"üìä Successfully processed {images_processed} images:\")\n",
    "        \n",
    "        # Count before and after images\n",
    "        before_count = sum(1 for r in results.values() if r['type'] == 'before')\n",
    "        after_count = sum(1 for r in results.values() if r['type'] == 'after')\n",
    "        \n",
    "        print(f\"   - {before_count} BEFORE fire images\")\n",
    "        print(f\"   - {after_count} AFTER fire images\")\n",
    "        print(f\"üìè Scale bars added to ALL images (2 km)\")\n",
    "        print(f\"üíæ All classification dashboards saved to: {CLASSIFIED_DIR}\")\n",
    "        \n",
    "        # List saved files\n",
    "        saved_files = [f for f in os.listdir(CLASSIFIED_DIR) if f.endswith('.png')]\n",
    "        if saved_files:\n",
    "            print(f\"\\nüìÅ Saved dashboard files:\")\n",
    "            for file in sorted(saved_files):\n",
    "                print(f\"   - {file}\")\n",
    "        \n",
    "        # Show directory location\n",
    "        print(f\"\\nüìÇ Classification Results Directory:\")\n",
    "        print(f\"   {CLASSIFIED_DIR}\")\n",
    "        \n",
    "        # Show comparison for first before/after pair if available\n",
    "        before_files = [f for f in results.keys() if results[f]['type'] == 'before']\n",
    "        after_files = [f for f in results.keys() if results[f]['type'] == 'after']\n",
    "        \n",
    "        if before_files and after_files:\n",
    "            before_file = sorted(before_files)[0]\n",
    "            after_file = sorted(after_files)[0]\n",
    "            \n",
    "            compare_before_after(\n",
    "                results[before_file]['stats'],\n",
    "                results[after_file]['stats'],\n",
    "                before_file,\n",
    "                after_file\n",
    "            )\n",
    "    else:\n",
    "        print(\"‚ùå No images were successfully processed.\")\n",
    "        print(\"üí° Please check that:\")\n",
    "        print(\"   - The extraction script has been run successfully\")\n",
    "        print(\"   - TIFF files exist in the preview directory\")\n",
    "        print(\"   - Files follow the naming pattern: square_10km_allbands_[before/after]_[fire_id]_[date].tif\")\n",
    "        print(f\"   - Source directory: {PREVIEW_DIR}\")\n",
    "\n",
    "# Run the corrected version\n",
    "if __name__ == \"__main__\":\n",
    "    main_corrected()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004fef8c-ca98-49bf-90c6-35f47b2621e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image as PILImage, ImageDraw\n",
    "import rasterio\n",
    "from IPython.display import display, HTML\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "# Configuration - UPDATED PATHS\n",
    "PREVIEW_DIR = r'C:\\Users\\steph\\Downloads\\master_thesis\\scripts\\sentinel2_fire_images\\preview'\n",
    "NBR_DIR = r'C:\\Users\\steph\\Downloads\\master_thesis\\scripts\\sentinel2_fire_images\\nbr_analysis'\n",
    "os.makedirs(NBR_DIR, exist_ok=True)\n",
    "\n",
    "# Burn severity classes based on NBR\n",
    "BURN_CLASSES = {\n",
    "    0: {'name': 'Enhanced Regrowth', 'color': (0, 100, 0), 'dNBR_range': '<-0.25'},\n",
    "    1: {'name': 'Unburned', 'color': (50, 205, 50), 'dNBR_range': '-0.25 to -0.1'},\n",
    "    2: {'name': 'Low Severity', 'color': (255, 255, 0), 'dNBR_range': '-0.1 to +0.1'},\n",
    "    3: {'name': 'Moderate Severity', 'color': (255, 165, 0), 'dNBR_range': '+0.1 to +0.27'},\n",
    "    4: {'name': 'High Severity', 'color': (255, 0, 0), 'dNBR_range': '>+0.27'}\n",
    "}\n",
    "\n",
    "def add_scale_bar_to_plot(ax, transform, scale_km=2):\n",
    "    \"\"\"Add a scale bar to matplotlib plot.\"\"\"\n",
    "    try:\n",
    "        # Get image dimensions in data coordinates\n",
    "        xlim = ax.get_xlim()\n",
    "        ylim = ax.get_ylim()\n",
    "        \n",
    "        # Calculate pixel size in meters using the transform\n",
    "        pixel_size_m = abs(transform[0])  # meters per pixel\n",
    "        \n",
    "        # Calculate scale bar length in pixels\n",
    "        scale_length_pixels = (scale_km * 1000) / pixel_size_m\n",
    "        \n",
    "        # Position in bottom right corner (5% from right, 5% from bottom)\n",
    "        x_range = xlim[1] - xlim[0]\n",
    "        y_range = ylim[1] - ylim[0]\n",
    "        \n",
    "        x_pos = xlim[1] - x_range * 0.05 - scale_length_pixels\n",
    "        y_pos = ylim[0] + y_range * 0.05\n",
    "        \n",
    "        # Draw scale bar\n",
    "        rect = plt.Rectangle((x_pos, y_pos), scale_length_pixels, y_range * 0.005,\n",
    "                           facecolor='white', edgecolor='black', linewidth=2)\n",
    "        ax.add_patch(rect)\n",
    "        \n",
    "        # Add scale text\n",
    "        ax.text(x_pos + scale_length_pixels / 2, y_pos - y_range * 0.02,\n",
    "               f'{scale_km} km', ha='center', va='top', color='white', \n",
    "               fontweight='bold', fontsize=10,\n",
    "               bbox=dict(boxstyle=\"round,pad=0.3\", facecolor='black', alpha=0.7))\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  ‚ö† Could not add scale bar to plot: {e}\")\n",
    "\n",
    "def identify_sentinel2_bands_for_nbr(bands):\n",
    "    \"\"\"Identify Sentinel-2 bands needed for NBR calculation.\"\"\"\n",
    "    print(f\"  - Number of bands: {len(bands)}\")\n",
    "    \n",
    "    band_info = {}\n",
    "    \n",
    "    if len(bands) >= 12:\n",
    "        # Standard 12-band Sentinel-2\n",
    "        band_info = {\n",
    "            'nir': bands[7],     # Band 8 - B08 (NIR)\n",
    "            'swir2': bands[11]   # Band 12 - B12 (SWIR)\n",
    "        }\n",
    "        print(\"  - Identified as 12-band Sentinel-2 (using B8 for NIR, B12 for SWIR)\")\n",
    "        \n",
    "    elif len(bands) >= 10:\n",
    "        # Try to identify by wavelength characteristics\n",
    "        band_means = [np.mean(band) for band in bands]\n",
    "        \n",
    "        # For NBR we need NIR (usually high reflectance) and SWIR (usually lower)\n",
    "        # NIR is typically band 7 or 8, SWIR is typically band 11 or 12\n",
    "        if len(bands) >= 8:\n",
    "            band_info = {\n",
    "                'nir': bands[7],   # Assume band 8 is NIR\n",
    "                'swir2': bands[10] if len(bands) > 10 else bands[9]  # Try band 11 or 10\n",
    "            }\n",
    "            print(\"  - Using bands 8 (NIR) and 11/10 (SWIR) for NBR\")\n",
    "    else:\n",
    "        # Fallback - try to find NIR and SWIR bands\n",
    "        band_means = [np.mean(band) for band in bands]\n",
    "        \n",
    "        # NIR usually has highest reflectance in vegetation\n",
    "        # SWIR usually has lower reflectance\n",
    "        nir_idx = np.argmax(band_means)\n",
    "        \n",
    "        # Find a band with lower reflectance (likely SWIR)\n",
    "        remaining = [i for i in range(len(bands)) if i != nir_idx]\n",
    "        if remaining:\n",
    "            swir_idx = remaining[np.argmin([band_means[i] for i in remaining])]\n",
    "            \n",
    "            band_info = {\n",
    "                'nir': bands[nir_idx],\n",
    "                'swir2': bands[swir_idx]\n",
    "            }\n",
    "            print(f\"  - Identified by reflectance: B{nir_idx+1}=NIR, B{swir_idx+1}=SWIR\")\n",
    "        else:\n",
    "            print(\"‚ùå Not enough bands for NBR calculation\")\n",
    "    \n",
    "    return band_info\n",
    "\n",
    "def calculate_nbr(nir, swir2):\n",
    "    \"\"\"Calculate Normalized Burn Ratio.\"\"\"\n",
    "    # Ensure we're working with float arrays\n",
    "    nir = nir.astype(np.float32)\n",
    "    swir2 = swir2.astype(np.float32)\n",
    "    \n",
    "    # Handle division by zero\n",
    "    denominator = nir + swir2\n",
    "    valid_mask = denominator > 0\n",
    "    \n",
    "    nbr = np.zeros_like(nir, dtype=np.float32)\n",
    "    nbr[valid_mask] = (nir[valid_mask] - swir2[valid_mask]) / denominator[valid_mask]\n",
    "    \n",
    "    # NBR should be between -1 and 1\n",
    "    nbr = np.clip(nbr, -1, 1)\n",
    "    \n",
    "    return nbr\n",
    "\n",
    "def calculate_dnbr(nbr_before, nbr_after):\n",
    "    \"\"\"Calculate differenced NBR (dNBR) for burn severity.\"\"\"\n",
    "    dNBR = nbr_before - nbr_after\n",
    "    return dNBR\n",
    "\n",
    "def classify_burn_severity(dNBR):\n",
    "    \"\"\"Classify burn severity based on dNBR values.\"\"\"\n",
    "    # USGS standard dNBR burn severity classes\n",
    "    classification = np.zeros(dNBR.shape, dtype=np.uint8)\n",
    "    \n",
    "    # Apply burn severity classification\n",
    "    classification[dNBR < -0.25] = 0   # Enhanced Regrowth\n",
    "    classification[(dNBR >= -0.25) & (dNBR < -0.1)] = 1   # Unburned\n",
    "    classification[(dNBR >= -0.1) & (dNBR < 0.1)] = 2     # Low Severity\n",
    "    classification[(dNBR >= 0.1) & (dNBR < 0.27)] = 3     # Moderate Severity\n",
    "    classification[dNBR >= 0.27] = 4                      # High Severity\n",
    "    \n",
    "    return classification\n",
    "\n",
    "def create_nbr_colormap(nbr):\n",
    "    \"\"\"Create a colored NBR visualization.\"\"\"\n",
    "    # Normalize NBR from -1 to 1 to 0 to 1\n",
    "    nbr_normalized = (nbr + 1) / 2\n",
    "    nbr_normalized = np.clip(nbr_normalized, 0, 1)\n",
    "    \n",
    "    # Use custom colormap for NBR\n",
    "    colors = [(0, 0.5, 0), (0, 1, 0), (1, 1, 0), (1, 0.5, 0), (1, 0, 0)]  # Green to Red\n",
    "    cmap = mcolors.LinearSegmentedColormap.from_list(\"nbr_cmap\", colors)\n",
    "    nbr_colored = (cmap(nbr_normalized) * 255).astype(np.uint8)[:, :, :3]\n",
    "    return nbr_colored\n",
    "\n",
    "def create_burn_severity_colormap(burn_classification):\n",
    "    \"\"\"Create a colored burn severity visualization.\"\"\"\n",
    "    height, width = burn_classification.shape\n",
    "    severity_rgb = np.zeros((height, width, 3), dtype=np.uint8)\n",
    "    \n",
    "    for class_id, class_info in BURN_CLASSES.items():\n",
    "        mask = burn_classification == class_id\n",
    "        severity_rgb[mask] = class_info['color']\n",
    "    \n",
    "    return severity_rgb\n",
    "\n",
    "def create_comprehensive_dashboard(nbr_before, nbr_after, dNBR, burn_severity, stats, before_file, after_file, transform):\n",
    "    \"\"\"Create a comprehensive dashboard figure with scale bars.\"\"\"\n",
    "    # Create visualizations\n",
    "    nbr_before_vis = create_nbr_colormap(nbr_before)\n",
    "    nbr_after_vis = create_nbr_colormap(nbr_after)\n",
    "    severity_vis = create_burn_severity_colormap(burn_severity)\n",
    "    \n",
    "    # Create figure with subplots\n",
    "    fig = plt.figure(figsize=(20, 16))\n",
    "    fig.suptitle(f'NBR Burn Severity Analysis: {before_file} vs {after_file}', \n",
    "                 fontsize=18, fontweight='bold', y=0.98)\n",
    "    \n",
    "    # Create grid layout\n",
    "    gs = fig.add_gridspec(3, 4, hspace=0.3, wspace=0.3)\n",
    "    \n",
    "    # Plot 1: NBR Before Fire\n",
    "    ax1 = fig.add_subplot(gs[0, 0])\n",
    "    ax1.imshow(nbr_before_vis)\n",
    "    add_scale_bar_to_plot(ax1, transform)\n",
    "    ax1.set_title('NBR - Before Fire\\n(Green=Healthy, Red=Stressed)', fontsize=12, fontweight='bold')\n",
    "    ax1.axis('off')\n",
    "    \n",
    "    # Plot 2: NBR After Fire\n",
    "    ax2 = fig.add_subplot(gs[0, 1])\n",
    "    ax2.imshow(nbr_after_vis)\n",
    "    add_scale_bar_to_plot(ax2, transform)\n",
    "    ax2.set_title('NBR - After Fire\\n(Green=Healthy, Red=Stressed)', fontsize=12, fontweight='bold')\n",
    "    ax2.axis('off')\n",
    "    \n",
    "    # Plot 3: dNBR (Difference)\n",
    "    ax3 = fig.add_subplot(gs[0, 2])\n",
    "    im = ax3.imshow(dNBR, cmap='RdYlGn_r', vmin=-0.5, vmax=0.5)\n",
    "    add_scale_bar_to_plot(ax3, transform)\n",
    "    ax3.set_title('dNBR (Before - After)\\n(Red=Burned, Green=Recovery)', fontsize=12, fontweight='bold')\n",
    "    ax3.axis('off')\n",
    "    plt.colorbar(im, ax=ax3, fraction=0.046, pad=0.04)\n",
    "    \n",
    "    # Plot 4: Burn Severity Classification\n",
    "    ax4 = fig.add_subplot(gs[0, 3])\n",
    "    ax4.imshow(severity_vis)\n",
    "    add_scale_bar_to_plot(ax4, transform)\n",
    "    ax4.set_title('Burn Severity Classification', fontsize=12, fontweight='bold')\n",
    "    ax4.axis('off')\n",
    "    \n",
    "    # Plot 5: Burn Severity Statistics\n",
    "    ax5 = fig.add_subplot(gs[1, :2])\n",
    "    classes = [BURN_CLASSES[class_id]['name'] for class_id in sorted(stats.keys())]\n",
    "    percentages = [stats[class_id]['percentage'] for class_id in sorted(stats.keys())]\n",
    "    colors = [tuple(c/255 for c in BURN_CLASSES[class_id]['color']) for class_id in sorted(stats.keys())]\n",
    "    \n",
    "    bars = ax5.bar(classes, percentages, color=colors, edgecolor='black', alpha=0.7)\n",
    "    ax5.set_title('Burn Severity Distribution (%)', fontsize=14, fontweight='bold')\n",
    "    ax5.set_ylabel('Percentage (%)', fontsize=12)\n",
    "    ax5.tick_params(axis='x', rotation=45)\n",
    "    ax5.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for bar, percentage in zip(bars, percentages):\n",
    "        height = bar.get_height()\n",
    "        ax5.text(bar.get_x() + bar.get_width()/2., height + 0.5,\n",
    "                f'{percentage:.1f}%', ha='center', va='bottom', fontweight='bold', fontsize=10)\n",
    "    \n",
    "    # Plot 6: dNBR Histogram\n",
    "    ax6 = fig.add_subplot(gs[1, 2:])\n",
    "    ax6.hist(dNBR.flatten(), bins=50, color='orange', alpha=0.7, edgecolor='black')\n",
    "    ax6.set_title('dNBR Value Distribution', fontsize=14, fontweight='bold')\n",
    "    ax6.set_xlabel('dNBR Value', fontsize=12)\n",
    "    ax6.set_ylabel('Pixel Count', fontsize=12)\n",
    "    ax6.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add dNBR class thresholds\n",
    "    thresholds = [-0.25, -0.1, 0.1, 0.27]\n",
    "    colors = ['green', 'lightgreen', 'yellow', 'orange', 'red']\n",
    "    threshold_labels = ['Enhanced Regrowth', 'Unburned', 'Low Severity', 'Moderate Severity', 'High Severity']\n",
    "    \n",
    "    for i, threshold in enumerate(thresholds):\n",
    "        ax6.axvline(x=threshold, color=colors[i], linestyle='--', alpha=0.7, label=threshold_labels[i])\n",
    "    \n",
    "    ax6.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    \n",
    "    # Plot 7: Text summary\n",
    "    ax7 = fig.add_subplot(gs[2, :])\n",
    "    ax7.axis('off')\n",
    "    \n",
    "    # Calculate summary statistics\n",
    "    burned_classes = [2, 3, 4]\n",
    "    total_burned = sum(stats[c]['pixels'] for c in burned_classes)\n",
    "    total_burned_pct = (total_burned / burn_severity.size) * 100\n",
    "    high_severity_pct = stats[4]['percentage']\n",
    "    \n",
    "    summary_text = [\n",
    "        \"BURN IMPACT SUMMARY:\",\n",
    "        f\"   * Total Burned Area: {total_burned_pct:.1f}%\",\n",
    "        f\"   * High Severity Burn: {high_severity_pct:.1f}%\",\n",
    "        f\"   * Moderate Severity Burn: {stats[3]['percentage']:.1f}%\",\n",
    "        f\"   * Low Severity Burn: {stats[2]['percentage']:.1f}%\",\n",
    "        f\"   * Unburned Area: {stats[1]['percentage']:.1f}%\",\n",
    "        f\"   * Enhanced Regrowth: {stats[0]['percentage']:.1f}%\",\n",
    "        \"\",\n",
    "        \"NBR STATISTICS:\",\n",
    "        f\"   * Pre-fire NBR Mean: {nbr_before.mean():.3f}\",\n",
    "        f\"   * Post-fire NBR Mean: {nbr_after.mean():.3f}\",\n",
    "        f\"   * dNBR Mean: {dNBR.mean():.3f}\",\n",
    "        f\"   * dNBR Range: [{dNBR.min():.3f}, {dNBR.max():.3f}]\",\n",
    "        \"\",\n",
    "        \"SCALE INFORMATION:\",\n",
    "        f\"   * Scale bars: 2 km (all images)\",\n",
    "        f\"   * Resolution: {abs(transform[0]):.1f} m/pixel\"\n",
    "    ]\n",
    "    \n",
    "    # Add fire impact assessment with text symbols\n",
    "    if total_burned_pct > 50:\n",
    "        impact = \"ALERT: EXTENSIVE FIRE - Over 50% of area burned\"\n",
    "    elif total_burned_pct > 25:\n",
    "        impact = \"WARNING: MAJOR FIRE - 25-50% of area burned\"\n",
    "    elif total_burned_pct > 10:\n",
    "        impact = \"MODERATE FIRE - 10-25% of area burned\"\n",
    "    else:\n",
    "        impact = \"LIMITED FIRE - Less than 10% of area burned\"\n",
    "    \n",
    "    if high_severity_pct > 20:\n",
    "        damage = \"ALERT: SEVERE DAMAGE - High severity burns over 20%\"\n",
    "    elif high_severity_pct > 10:\n",
    "        damage = \"WARNING: SIGNIFICANT DAMAGE - High severity burns 10-20%\"\n",
    "    else:\n",
    "        damage = \"MINOR DAMAGE - High severity burns under 10%\"\n",
    "    \n",
    "    summary_text.extend([\n",
    "        \"\",\n",
    "        \"FIRE IMPACT ASSESSMENT:\",\n",
    "        f\"   * {impact}\",\n",
    "        f\"   * {damage}\"\n",
    "    ])\n",
    "    \n",
    "    ax7.text(0.02, 0.95, \"\\n\".join(summary_text), transform=ax7.transAxes, \n",
    "             fontsize=12, verticalalignment='top', fontfamily='monospace',\n",
    "             bbox=dict(boxstyle=\"round,pad=0.5\", facecolor=\"lightgray\", alpha=0.7))\n",
    "    \n",
    "    return fig\n",
    "\n",
    "def save_dashboard_as_png(nbr_before, nbr_after, dNBR, burn_severity, stats, before_file, after_file, output_dir, transform):\n",
    "    \"\"\"Save only the dashboard as PNG.\"\"\"\n",
    "    base_name = f\"{os.path.splitext(before_file)[0]}_vs_{os.path.splitext(after_file)[0]}\"\n",
    "    \n",
    "    # Create and save comprehensive dashboard\n",
    "    fig = create_comprehensive_dashboard(nbr_before, nbr_after, dNBR, burn_severity, stats, before_file, after_file, transform)\n",
    "    dashboard_path = os.path.join(output_dir, f\"{base_name}_dashboard.png\")\n",
    "    fig.savefig(dashboard_path, dpi=300, bbox_inches='tight', facecolor='white')\n",
    "    plt.close(fig)\n",
    "    \n",
    "    print(f\"üíæ Dashboard saved as: {dashboard_path}\")\n",
    "    return dashboard_path\n",
    "\n",
    "def display_nbr_analysis(nbr_before, nbr_after, dNBR, burn_severity, stats, before_file, after_file, transform):\n",
    "    \"\"\"Display comprehensive NBR analysis results and save only dashboard as PNG.\"\"\"\n",
    "    # Create and display the dashboard\n",
    "    fig = create_comprehensive_dashboard(nbr_before, nbr_after, dNBR, burn_severity, stats, before_file, after_file, transform)\n",
    "    \n",
    "    # Display in notebook\n",
    "    display(HTML(f\"<h2>üî• NBR BURN SEVERITY ANALYSIS</h2>\"))\n",
    "    display(HTML(f\"<h3>Before: {before_file} | After: {after_file}</h3>\"))\n",
    "    plt.show()\n",
    "    \n",
    "    # Save only dashboard as PNG\n",
    "    dashboard_path = save_dashboard_as_png(nbr_before, nbr_after, dNBR, burn_severity, stats, before_file, after_file, NBR_DIR, transform)\n",
    "    \n",
    "    # Display detailed statistics in console WITH EMOJIS\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üî• BURN SEVERITY STATISTICS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Sort by burn severity (descending)\n",
    "    sorted_stats = sorted(stats.items(), key=lambda x: x[1]['percentage'], reverse=True)\n",
    "    \n",
    "    for class_id, stat in sorted_stats:\n",
    "        print(f\"üè∑Ô∏è  {stat['name']:25} {stat['percentage']:6.2f}% ({stat['pixels']:>8,} pixels)\")\n",
    "    \n",
    "    # Burn impact summary\n",
    "    burned_classes = [2, 3, 4]  # Low, Moderate, High severity\n",
    "    total_burned = sum(stats[c]['pixels'] for c in burned_classes)\n",
    "    total_burned_pct = (total_burned / burn_severity.size) * 100\n",
    "    high_severity_pct = stats[4]['percentage']\n",
    "    \n",
    "    print(f\"\\nüìä BURN IMPACT SUMMARY:\")\n",
    "    print(f\"   Total Burned Area: {total_burned_pct:.1f}%\")\n",
    "    print(f\"   High Severity Burn: {high_severity_pct:.1f}%\")\n",
    "    print(f\"   Moderate Severity Burn: {stats[3]['percentage']:.1f}%\")\n",
    "    print(f\"   Low Severity Burn: {stats[2]['percentage']:.1f}%\")\n",
    "    print(f\"   Unburned Area: {stats[1]['percentage']:.1f}%\")\n",
    "    print(f\"   Enhanced Regrowth: {stats[0]['percentage']:.1f}%\")\n",
    "    \n",
    "    # NBR statistics\n",
    "    print(f\"\\nüéØ NBR STATISTICS:\")\n",
    "    print(f\"   Pre-fire NBR Range: [{nbr_before.min():.3f}, {nbr_before.max():.3f}]\")\n",
    "    print(f\"   Pre-fire NBR Mean: {nbr_before.mean():.3f}\")\n",
    "    print(f\"   Post-fire NBR Range: [{nbr_after.min():.3f}, {nbr_after.max():.3f}]\")\n",
    "    print(f\"   Post-fire NBR Mean: {nbr_after.mean():.3f}\")\n",
    "    print(f\"   dNBR Range: [{dNBR.min():.3f}, {dNBR.max():.3f}]\")\n",
    "    print(f\"   dNBR Mean: {dNBR.mean():.3f}\")\n",
    "    \n",
    "    # Scale information\n",
    "    print(f\"\\nüìè SCALE INFORMATION:\")\n",
    "    print(f\"   Scale bars: 2 km (added to all images)\")\n",
    "    print(f\"   Resolution: {abs(transform[0]):.1f} meters/pixel\")\n",
    "    \n",
    "    # Fire impact assessment WITH EMOJIS\n",
    "    print(f\"\\nüî• FIRE IMPACT ASSESSMENT:\")\n",
    "    if total_burned_pct > 50:\n",
    "        print(\"   üö® EXTENSIVE FIRE: Over 50% of area burned\")\n",
    "    elif total_burned_pct > 25:\n",
    "        print(\"   ‚ö†Ô∏è  MAJOR FIRE: 25-50% of area burned\")\n",
    "    elif total_burned_pct > 10:\n",
    "        print(\"   üî• MODERATE FIRE: 10-25% of area burned\")\n",
    "    else:\n",
    "        print(\"   ‚úÖ LIMITED FIRE: Less than 10% of area burned\")\n",
    "    \n",
    "    if high_severity_pct > 20:\n",
    "        print(\"   üö® SEVERE DAMAGE: High severity burns over 20%\")\n",
    "    elif high_severity_pct > 10:\n",
    "        print(\"   ‚ö†Ô∏è  SIGNIFICANT DAMAGE: High severity burns 10-20%\")\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    return dashboard_path\n",
    "\n",
    "def process_nbr_analysis(before_file, after_file):\n",
    "    \"\"\"Process NBR analysis for before and after fire images.\"\"\"\n",
    "    before_path = os.path.join(PREVIEW_DIR, before_file)\n",
    "    after_path = os.path.join(PREVIEW_DIR, after_file)\n",
    "    \n",
    "    try:\n",
    "        print(f\"\\nüî• PROCESSING NBR ANALYSIS\")\n",
    "        print(f\"   Before: {before_file}\")\n",
    "        print(f\"   After: {after_file}\")\n",
    "        \n",
    "        # Process before image\n",
    "        with rasterio.open(before_path) as src_before:\n",
    "            print(f\"\\nüîÑ Reading BEFORE image...\")\n",
    "            print(f\"   Resolution: {abs(src_before.transform[0]):.1f} m/pixel\")\n",
    "            bands_before = []\n",
    "            for i in range(1, src_before.count + 1):\n",
    "                bands_before.append(src_before.read(i))\n",
    "            \n",
    "            band_info_before = identify_sentinel2_bands_for_nbr(bands_before)\n",
    "            \n",
    "            if 'nir' not in band_info_before or 'swir2' not in band_info_before:\n",
    "                print(\"‚ùå Missing required bands for NBR calculation in BEFORE image\")\n",
    "                return None, None, None, None, None, None, None\n",
    "            \n",
    "            nbr_before = calculate_nbr(band_info_before['nir'], band_info_before['swir2'])\n",
    "        \n",
    "        # Process after image\n",
    "        with rasterio.open(after_path) as src_after:\n",
    "            print(f\"\\nüîÑ Reading AFTER image...\")\n",
    "            print(f\"   Resolution: {abs(src_after.transform[0]):.1f} m/pixel\")\n",
    "            bands_after = []\n",
    "            for i in range(1, src_after.count + 1):\n",
    "                bands_after.append(src_after.read(i))\n",
    "            \n",
    "            band_info_after = identify_sentinel2_bands_for_nbr(bands_after)\n",
    "            \n",
    "            if 'nir' not in band_info_after or 'swir2' not in band_info_after:\n",
    "                print(\"‚ùå Missing required bands for NBR calculation in AFTER image\")\n",
    "                return None, None, None, None, None, None, None\n",
    "            \n",
    "            nbr_after = calculate_nbr(band_info_after['nir'], band_info_after['swir2'])\n",
    "        \n",
    "        # Calculate dNBR and burn severity\n",
    "        dNBR = calculate_dnbr(nbr_before, nbr_after)\n",
    "        burn_severity = classify_burn_severity(dNBR)\n",
    "        \n",
    "        # Calculate statistics\n",
    "        total_pixels = burn_severity.size\n",
    "        stats = {}\n",
    "        for class_id, class_info in BURN_CLASSES.items():\n",
    "            class_pixels = np.sum(burn_severity == class_id)\n",
    "            stats[class_id] = {\n",
    "                'name': class_info['name'],\n",
    "                'percentage': (class_pixels / total_pixels) * 100,\n",
    "                'pixels': class_pixels\n",
    "            }\n",
    "        \n",
    "        # Display comprehensive analysis and save only dashboard\n",
    "        dashboard_path = display_nbr_analysis(nbr_before, nbr_after, dNBR, burn_severity, stats, before_file, after_file, src_before.transform)\n",
    "        \n",
    "        return nbr_before, nbr_after, dNBR, burn_severity, stats, dashboard_path, src_before.transform\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error processing NBR analysis: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None, None, None, None, None, None, None\n",
    "\n",
    "def find_and_group_image_files():\n",
    "    \"\"\"Find all image files and group them by fire ID.\"\"\"\n",
    "    if not os.path.exists(PREVIEW_DIR):\n",
    "        return {}, {}\n",
    "    \n",
    "    all_files = [f for f in os.listdir(PREVIEW_DIR) \n",
    "                if f.endswith(('.tif', '.tiff')) and 'square_10km' in f]\n",
    "    \n",
    "    # Group files by fire ID\n",
    "    fire_groups = {}\n",
    "    for file in all_files:\n",
    "        # Extract fire ID from filename (e.g., square_10km_allbands_before_001_20231015.tif)\n",
    "        import re\n",
    "        fire_match = re.search(r'_(\\d{3})_', file)\n",
    "        if fire_match:\n",
    "            fire_id = fire_match.group(1)\n",
    "            if fire_id not in fire_groups:\n",
    "                fire_groups[fire_id] = {'before': [], 'after': []}\n",
    "            \n",
    "            if 'before' in file.lower():\n",
    "                fire_groups[fire_id]['before'].append(file)\n",
    "            elif 'after' in file.lower():\n",
    "                fire_groups[fire_id]['after'].append(file)\n",
    "    \n",
    "    return all_files, fire_groups\n",
    "\n",
    "def display_all_nbr_analyses_with_messages():\n",
    "    \"\"\"Display all NBR analyses with proper grouping and clear 'no image' messages.\"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üî• DISPLAYING ALL NBR BURN SEVERITY ANALYSES\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Find and group all image files\n",
    "    all_files, fire_groups = find_and_group_image_files()\n",
    "    \n",
    "    if not all_files:\n",
    "        print(\"‚ùå No square_10km TIFF files found in the directory.\")\n",
    "        print(\"\\nüìÅ Available files in directory:\")\n",
    "        available_files = [f for f in os.listdir(PREVIEW_DIR) if f.endswith(('.tif', '.tiff'))]\n",
    "        if available_files:\n",
    "            for file in sorted(available_files):\n",
    "                print(f\"  - {file}\")\n",
    "        else:\n",
    "            print(\"  No TIFF files found.\")\n",
    "        return 0, {}\n",
    "    \n",
    "    print(f\"üìä Found {len(all_files)} total images across {len(fire_groups)} fire locations\")\n",
    "    \n",
    "    # Store results\n",
    "    results = {}\n",
    "    analyses_completed = 0\n",
    "    \n",
    "    # Process each fire location\n",
    "    for fire_id in sorted(fire_groups.keys()):\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"üî• FIRE LOCATION {fire_id}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        # Check for before/after pairs\n",
    "        before_images = fire_groups[fire_id]['before']\n",
    "        after_images = fire_groups[fire_id]['after']\n",
    "        \n",
    "        if not before_images:\n",
    "            print(f\"\\n‚ùå No BEFORE images available for fire {fire_id} - cannot perform NBR analysis\")\n",
    "            continue\n",
    "            \n",
    "        if not after_images:\n",
    "            print(f\"\\n‚ùå No AFTER images available for fire {fire_id} - cannot perform NBR analysis\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"\\nüîÑ PROCESSING NBR ANALYSIS FOR FIRE {fire_id}\")\n",
    "        print(f\"   Before images: {len(before_images)}\")\n",
    "        print(f\"   After images: {len(after_images)}\")\n",
    "        \n",
    "        # Process first before/after pair for each fire\n",
    "        before_file = sorted(before_images)[0]\n",
    "        after_file = sorted(after_images)[0]\n",
    "        \n",
    "        nbr_before, nbr_after, dNBR, burn_severity, stats, dashboard_path, transform = process_nbr_analysis(before_file, after_file)\n",
    "        \n",
    "        if burn_severity is not None:\n",
    "            results[fire_id] = {\n",
    "                'before_file': before_file,\n",
    "                'after_file': after_file,\n",
    "                'stats': stats,\n",
    "                'dashboard': dashboard_path,\n",
    "                'nbr_before': nbr_before,\n",
    "                'nbr_after': nbr_after,\n",
    "                'dNBR': dNBR\n",
    "            }\n",
    "            analyses_completed += 1\n",
    "            print(f\"‚úÖ NBR analysis completed for fire {fire_id}\")\n",
    "        else:\n",
    "            print(f\"‚ùå NBR analysis failed for fire {fire_id}\")\n",
    "    \n",
    "    return analyses_completed, results\n",
    "\n",
    "def main_nbr_analysis():\n",
    "    \"\"\"Main function for NBR burn severity analysis with complete looping.\"\"\"\n",
    "    print(\"‚úÖ üî• NORMALIZED BURN RATIO (NBR) ANALYSIS\")\n",
    "    print(\"=\" * 80)\n",
    "    print(\"üéØ Burn Severity Assessment using dNBR (differenced NBR)\")\n",
    "    print(\"üéØ Requires both BEFORE and AFTER fire images\")\n",
    "    print(\"üìè Scale bars: 2 km (added to ALL images)\")\n",
    "    print(f\"üíæ Results saved to: {NBR_DIR}\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    if not os.path.exists(PREVIEW_DIR):\n",
    "        print(f\"‚ùå Directory not found: {PREVIEW_DIR}\")\n",
    "        print(\"Please run the extraction script first to generate image files.\")\n",
    "        return\n",
    "    \n",
    "    # Display all NBR analyses with proper messaging\n",
    "    analyses_completed, results = display_all_nbr_analyses_with_messages()\n",
    "    \n",
    "    # Print summary\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"‚úÖ NBR ANALYSIS COMPLETED\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    if analyses_completed > 0:\n",
    "        print(f\"üìä Successfully completed {analyses_completed} NBR analyses:\")\n",
    "        \n",
    "        for fire_id, result in results.items():\n",
    "            burned_classes = [2, 3, 4]\n",
    "            total_burned = sum(result['stats'][c]['pixels'] for c in burned_classes)\n",
    "            total_burned_pct = (total_burned / result['dNBR'].size) * 100\n",
    "            \n",
    "            print(f\"   üî• Fire {fire_id}: {total_burned_pct:.1f}% burned area\")\n",
    "            print(f\"      - Before: {result['before_file']}\")\n",
    "            print(f\"      - After: {result['after_file']}\")\n",
    "            print(f\"      - Dashboard: {os.path.basename(result['dashboard'])}\")\n",
    "        \n",
    "        print(f\"üìè Scale bars added to ALL images (2 km)\")\n",
    "        print(f\"üíæ All NBR dashboards saved to: {NBR_DIR}\")\n",
    "        \n",
    "        # List saved files\n",
    "        saved_files = [f for f in os.listdir(NBR_DIR) if f.endswith('.png')]\n",
    "        if saved_files:\n",
    "            print(f\"\\nüìÅ Saved NBR dashboard files:\")\n",
    "            for file in sorted(saved_files):\n",
    "                print(f\"   - {file}\")\n",
    "        \n",
    "        # Show directory location\n",
    "        print(f\"\\nüìÇ NBR Analysis Directory:\")\n",
    "        print(f\"   {NBR_DIR}\")\n",
    "        \n",
    "    else:\n",
    "        print(\"‚ùå No NBR analyses were completed.\")\n",
    "        print(\"üí° Please check that:\")\n",
    "        print(\"   - Both BEFORE and AFTER images exist for at least one fire location\")\n",
    "        print(\"   - Images contain the required NIR and SWIR bands\")\n",
    "        print(\"   - Files follow the naming pattern: square_10km_allbands_[before/after]_[fire_id]_[date].tif\")\n",
    "        print(f\"   - Source directory: {PREVIEW_DIR}\")\n",
    "\n",
    "# Run the NBR analysis\n",
    "if __name__ == \"__main__\":\n",
    "    main_nbr_analysis()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
